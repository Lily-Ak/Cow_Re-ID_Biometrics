# -*- coding: utf-8 -*-
"""CNN_CowReID.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CRTGceuGDpIWb2rJjLpQy-PXfJA2ApRg
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import time
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score
import seaborn as sns

# Directories for training and validation data
train_dir = '/content/drive/MyDrive/Colab Notebooks/Biometrics_Projects/BetterData/train'
validation_dir = '/content/drive/MyDrive/Colab Notebooks/Biometrics_Projects/BetterData/val'

# Data augmentation and normalization
train_transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

validation_transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Data loaders
train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

validation_dataset = datasets.ImageFolder(validation_dir, transform=validation_transform)
validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)

class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=112, kernel_size=3, stride=1, padding=1),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.ReLU(),
            nn.Dropout(0.25),  # dropout layer with 25% dropout probability
            nn.Conv2d(in_channels=112, out_channels=56, kernel_size=3, stride=1, padding=1),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.ReLU(),
            nn.Dropout(0.25),
            nn.Conv2d(in_channels=56, out_channels=4, kernel_size=3, stride=1, padding=1),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.ReLU(),
            nn.Dropout(0.25)
        )
        self.fc = nn.Sequential(
            nn.Linear(in_features=4*28*28, out_features=784),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(in_features=784, out_features=6)
        )

    def forward(self, x):
        x = self.conv(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

model = CNN()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# loss and optimizer
loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Start a timer
start_time = time.time()

loss_list = []
accuracy_list = []

for epoch in range(50):
    epoch_loss = 0
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    loss_list.append(epoch_loss / len(train_loader))

    # Calculating training accuracy
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        accuracy = correct / total
        accuracy_list.append(accuracy)

    print(f'Epoch {epoch + 1} of 50. Training accuracy: {accuracy_list[-1]} and Loss of: {loss_list[-1]}')

# Display training time
total_time = int((time.time() - start_time) // 60)
print(f'Training Time:  {total_time} minutes')

# Evaluating the validation data
all_labels = []
all_predictions = []
with torch.no_grad():
    for images, labels in validation_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        all_labels.extend(labels.cpu().numpy())
        all_predictions.extend(predicted.cpu().numpy())

# Metrics
accuracy = accuracy_score(all_labels, all_predictions)
precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')
conf_matrix = confusion_matrix(all_labels, all_predictions)

print(f'Validation Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

# Confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# loss over epochs
x = range(50)
plt.plot(x, loss_list, label='Training Loss')
plt.xlabel('Number of Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()